{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install pandas\n",
    "# %pip install numpy\n",
    "# %pip install scikit-learn\n",
    "# %pip install kagglehub\n",
    "# %pip install cupy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-29T16:54:24.574362Z",
     "iopub.status.busy": "2024-12-29T16:54:24.573960Z",
     "iopub.status.idle": "2024-12-29T16:54:25.867960Z",
     "shell.execute_reply": "2024-12-29T16:54:25.866721Z",
     "shell.execute_reply.started": "2024-12-29T16:54:24.574325Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\patry\\anaconda3\\envs\\weather\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# from sklearn.preprocessing import LabelEncoder\n",
    "import kagglehub\n",
    "import cupy as cp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-29T16:54:25.869990Z",
     "iopub.status.busy": "2024-12-29T16:54:25.869419Z",
     "iopub.status.idle": "2024-12-29T16:54:29.158623Z",
     "shell.execute_reply": "2024-12-29T16:54:29.157504Z",
     "shell.execute_reply.started": "2024-12-29T16:54:25.869950Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# def get_aggregated_data_for_single_city():\n",
    "#     historical_hourly_weather_data_path = kagglehub.dataset_download('selfishgene/historical-hourly-weather-data')\n",
    "\n",
    "#     city = \"Portland\"\n",
    "\n",
    "#     city_attributes = pd.read_csv(f\"{historical_hourly_weather_data_path}/city_attributes.csv\")\n",
    "#     humidity = pd.read_csv(f\"{historical_hourly_weather_data_path}/humidity.csv\")\n",
    "#     pressure = pd.read_csv(f\"{historical_hourly_weather_data_path}/pressure.csv\")\n",
    "#     temperature = pd.read_csv(f\"{historical_hourly_weather_data_path}/temperature.csv\")\n",
    "#     weather_description = pd.read_csv(f\"{historical_hourly_weather_data_path}/weather_description.csv\")\n",
    "#     wind_speed = pd.read_csv(f\"{historical_hourly_weather_data_path}/wind_speed.csv\")\n",
    "#     wind_direction = pd.read_csv(f\"{historical_hourly_weather_data_path}/wind_direction.csv\")\n",
    "#     if city not in city_attributes['City'].values:\n",
    "#         raise ValueError(f\"City '{city}' does not exist in the data. Available cities are: {city_attributes['City'].unique()}\")\n",
    "\n",
    "#     selected_city = city_attributes[city_attributes['City'] == city].index[0]\n",
    "#     data_frames = [humidity, pressure, temperature, weather_description, wind_speed, wind_direction]\n",
    "\n",
    "#     for i, df in enumerate(data_frames):\n",
    "#         df.set_index('datetime', inplace=True)\n",
    "#         data_frames[i] = df.iloc[:, selected_city]\n",
    "#     combined_data = pd.concat(data_frames, axis=1)\n",
    "#     combined_data.columns = [\n",
    "#         'humidity', 'pressure', 'temperature', 'weather_description', \n",
    "#         'wind_speed', 'wind_direction'\n",
    "#     ]\n",
    "#     combined_data.index = pd.to_datetime(combined_data.index)\n",
    "\n",
    "#     # aggregate daily\n",
    "#     aggregated_data = combined_data.resample('D').agg({\n",
    "#         'temperature': 'mean',\n",
    "#         'humidity': 'mean',\n",
    "#         'wind_speed': ['max', 'mean'],\n",
    "#         'pressure': 'mean',\n",
    "#         'weather_description': lambda x: x.mode()[0] if not x.mode().empty else np.nan,\n",
    "#         'wind_direction': 'mean'\n",
    "#     })\n",
    "#     aggregated_data.columns = ['_'.join(col).strip('_') for col in aggregated_data.columns.values]\n",
    "\n",
    "#     return aggregated_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-29T16:54:29.161394Z",
     "iopub.status.busy": "2024-12-29T16:54:29.160941Z",
     "iopub.status.idle": "2024-12-29T16:54:29.178700Z",
     "shell.execute_reply": "2024-12-29T16:54:29.177526Z",
     "shell.execute_reply.started": "2024-12-29T16:54:29.161353Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# encoder = LabelEncoder()\n",
    "# aggregated_data['weather_description'] = encoder.fit_transform(aggregated_data['weather_description'])\n",
    "# weather_mapping = dict(enumerate(encoder.classes_))\n",
    "# print(\"Mapping for weather_description:\", weather_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\patry\\AppData\\Local\\Temp\\ipykernel_1332\\263827200.py:30: FutureWarning: DataFrame.interpolate with object dtype is deprecated and will raise in a future version. Call obj.infer_objects(copy=False) before interpolating instead.\n",
      "  combined_data = combined_data.ffill().bfill().interpolate()\n"
     ]
    }
   ],
   "source": [
    "historical_hourly_weather_data_path = kagglehub.dataset_download('selfishgene/historical-hourly-weather-data')\n",
    "\n",
    "city_attributes = pd.read_csv(f\"{historical_hourly_weather_data_path}/city_attributes.csv\")\n",
    "humidity = pd.read_csv(f\"{historical_hourly_weather_data_path}/humidity.csv\")\n",
    "pressure = pd.read_csv(f\"{historical_hourly_weather_data_path}/pressure.csv\")\n",
    "temperature = pd.read_csv(f\"{historical_hourly_weather_data_path}/temperature.csv\")\n",
    "weather_description = pd.read_csv(f\"{historical_hourly_weather_data_path}/weather_description.csv\")\n",
    "wind_speed = pd.read_csv(f\"{historical_hourly_weather_data_path}/wind_speed.csv\")\n",
    "wind_direction = pd.read_csv(f\"{historical_hourly_weather_data_path}/wind_direction.csv\")\n",
    "\n",
    "data_frames = []\n",
    "for city in city_attributes['City']:\n",
    "    city_data = pd.DataFrame({\n",
    "        'datetime': pd.to_datetime(humidity['datetime']),\n",
    "        'humidity': humidity[city],\n",
    "        'pressure': pressure[city],\n",
    "        'temperature': temperature[city],\n",
    "        'weather_description': weather_description[city],\n",
    "        'wind_speed': wind_speed[city],\n",
    "        'wind_direction': wind_direction[city],\n",
    "        'latitude': city_attributes.loc[city_attributes['City'] == city, 'Latitude'].values[0],\n",
    "        'longitude': city_attributes.loc[city_attributes['City'] == city, 'Longitude'].values[0],\n",
    "        'city': city\n",
    "    })\n",
    "    city_data.set_index('datetime', inplace=True)\n",
    "    data_frames.append(city_data)\n",
    "\n",
    "combined_data = pd.concat(data_frames)\n",
    "\n",
    "combined_data = combined_data.ffill().bfill().interpolate()\n",
    "\n",
    "aggregated_data = combined_data.groupby(['city']).resample('D').agg({\n",
    "    'temperature': 'mean',\n",
    "    'humidity': 'mean',\n",
    "    'wind_speed': ['max', 'mean'],\n",
    "    'pressure': 'mean',\n",
    "    'weather_description': lambda x: x.mode()[0] if not x.mode().empty else np.nan,\n",
    "    'wind_direction': 'mean',\n",
    "    'latitude': 'mean',\n",
    "    'longitude': 'mean'\n",
    "}).reset_index()\n",
    "\n",
    "aggregated_data.columns = [\n",
    "    '_'.join(col).strip('_') if isinstance(col, tuple) else col for col in aggregated_data.columns\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def preprocess_weather_data_for_single_city(data, window_size=3):\n",
    "#     X, y = [], []\n",
    "#     for i in range(window_size, len(data) - 1):\n",
    "#         X_window = data.iloc[i-window_size:i][[\n",
    "#             'temperature_mean', 'humidity_mean', 'pressure_mean', 'wind_speed_max', 'wind_speed_mean', 'wind_direction_mean'\n",
    "#         ]].values\n",
    "#         y_target = data.iloc[i + 1][['temperature_mean', 'wind_speed_max']].values\n",
    "\n",
    "#         # encode wind speed >= 6 as binary\n",
    "#         y_target[1] = 1 if y_target[1] >= 6 else 0\n",
    "#         X.append(X_window)\n",
    "#         y.append(y_target)\n",
    "\n",
    "#     X = np.array(X)\n",
    "#     y = np.array(y)\n",
    "\n",
    "#     # normalize X\n",
    "#     X_mean = X.mean(axis=(0, 1), keepdims=True)\n",
    "#     X_std = X.std(axis=(0, 1), keepdims=True)\n",
    "#     X_normalized = (X - X_mean) / (X_std + 1e-9)\n",
    "\n",
    "#     return X_normalized, y\n",
    "\n",
    "def preprocess_weather_data(data, window_size=3):\n",
    "    X, y = [], []\n",
    "    for i in range(window_size, len(data) - 1):\n",
    "        X_window = data.iloc[i-window_size:i][[\n",
    "            'temperature_mean', 'humidity_mean', 'pressure_mean', 'wind_speed_max', 'wind_speed_mean', 'wind_direction_mean', 'latitude_mean', 'longitude_mean'\n",
    "        ]].values\n",
    "        y_target = data.iloc[i + 1][['temperature_mean', 'wind_speed_max']].values\n",
    "\n",
    "        # encode wind speed >= 6 as binary\n",
    "        y_target[1] = 1 if y_target[1] >= 6 else 0\n",
    "        X.append(X_window)\n",
    "        y.append(y_target)\n",
    "\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "\n",
    "    # normalize X\n",
    "    X_mean = X.mean(axis=(0, 1), keepdims=True)\n",
    "    X_std = X.std(axis=(0, 1), keepdims=True)\n",
    "    X_normalized = (X - X_mean) / (X_std + 1e-9)\n",
    "\n",
    "    return X_normalized, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = preprocess_weather_data(aggregated_data, window_size=3)\n",
    "\n",
    "# split into train/test (0.7 or 0.8)\n",
    "train_size = int(0.8 * len(X))\n",
    "X_train, X_test = X[:train_size], X[train_size:]\n",
    "y_train, y_test = y[:train_size], y[train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(54342, 3, 8)\n",
      "(54342, 2)\n",
      "(13586, 3, 8)\n",
      "(13586, 2)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(X_train)\n",
    "# print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate(model, X_train, y_train, X_test, y_test, epochs=1000, learning_rate=0.001, bath_size=128):\n",
    "    X_train_cp = cp.array(X_train.reshape(X_train.shape[0], -1), dtype=cp.float32)\n",
    "    y_train_cp = cp.array(y_train, dtype=cp.float32)\n",
    "    X_test_cp = cp.array(X_test.reshape(X_test.shape[0], -1), dtype=cp.float32)\n",
    "    y_test_cp = cp.array(y_test, dtype=cp.float32)\n",
    "\n",
    "    model.train(X_train_cp, y_train_cp, X_test_cp, y_test_cp, epochs, learning_rate, batch_size=bath_size)\n",
    "\n",
    "    predictions = model.predict(X_test_cp)\n",
    "    \n",
    "    mae = cp.mean(cp.abs(predictions[:, 0] - y_test_cp[:, 0]))\n",
    "\n",
    "    from sklearn.metrics import roc_auc_score\n",
    "    auc = roc_auc_score(cp.asnumpy(y_test_cp[:, 1]), cp.asnumpy(predictions[:, 1]))\n",
    "\n",
    "    print(f\"Test Regression MAE: {mae}\")\n",
    "    print(f\"Test Classification AUC: {auc}\")\n",
    "\n",
    "    print(\"Predictions:\" , predictions[:5, :])\n",
    "    print(\"True values:\", y_test_cp[:5, :])\n",
    "\n",
    "    return mae, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Regression Loss: 29.0032901763916, Classification AUC: 0.5704383964646578, Learning Rate: 0.001\n",
      "Test Regression MAE: 39.77280044555664, Test Classification AUC: 0.5\n",
      "Epoch 100, Regression Loss: 3.3196463584899902, Classification AUC: 0.6779207694597101, Learning Rate: 0.001\n",
      "Epoch 200, Regression Loss: 3.443655252456665, Classification AUC: 0.7159709576368334, Learning Rate: 0.001\n",
      "Epoch 300, Regression Loss: 3.4750566482543945, Classification AUC: 0.7178535418710441, Learning Rate: 0.001\n",
      "Epoch 400, Regression Loss: 3.313891887664795, Classification AUC: 0.7231865495033699, Learning Rate: 0.001\n",
      "Epoch 500, Regression Loss: 3.3306355476379395, Classification AUC: 0.7305777628048009, Learning Rate: 0.0001\n",
      "Epoch 600, Regression Loss: 2.5916759967803955, Classification AUC: 0.7412842597836671, Learning Rate: 0.0001\n",
      "Epoch 700, Regression Loss: 2.581341028213501, Classification AUC: 0.7445192796402623, Learning Rate: 0.0001\n",
      "Epoch 800, Regression Loss: 2.5990467071533203, Classification AUC: 0.7468272871403636, Learning Rate: 0.0001\n",
      "Epoch 900, Regression Loss: 2.58425235748291, Classification AUC: 0.747944937754387, Learning Rate: 0.0001\n",
      "Epoch 1000, Regression Loss: 2.5652153491973877, Classification AUC: 0.7492401024548787, Learning Rate: 1e-05\n",
      "Test Regression MAE: 2.1808626651763916, Test Classification AUC: 0.6619498928477249\n",
      "Epoch 1100, Regression Loss: 2.5433785915374756, Classification AUC: 0.749420988127629, Learning Rate: 1e-05\n",
      "Epoch 1200, Regression Loss: 2.5435190200805664, Classification AUC: 0.7495782335238784, Learning Rate: 1e-05\n",
      "Epoch 1300, Regression Loss: 2.542140007019043, Classification AUC: 0.7497830529234641, Learning Rate: 1e-05\n",
      "Epoch 1400, Regression Loss: 2.542041540145874, Classification AUC: 0.7499832059816609, Learning Rate: 1e-05\n",
      "Epoch 1500, Regression Loss: 2.545707941055298, Classification AUC: 0.7501007318098811, Learning Rate: 1.0000000000000002e-06\n",
      "Epoch 1600, Regression Loss: 2.540947437286377, Classification AUC: 0.7501298603636031, Learning Rate: 1.0000000000000002e-06\n",
      "Epoch 1700, Regression Loss: 2.5408437252044678, Classification AUC: 0.7501439404817736, Learning Rate: 1.0000000000000002e-06\n",
      "Epoch 1800, Regression Loss: 2.541355609893799, Classification AUC: 0.7501657932540103, Learning Rate: 1.0000000000000002e-06\n",
      "Epoch 1900, Regression Loss: 2.540485382080078, Classification AUC: 0.7501789297953432, Learning Rate: 1.0000000000000002e-06\n",
      "Epoch 2000, Regression Loss: 2.5405783653259277, Classification AUC: 0.7501966557074856, Learning Rate: 1.0000000000000002e-07\n",
      "Test Regression MAE: 2.1641173362731934, Test Classification AUC: 0.6580858404949468\n",
      "Epoch 2100, Regression Loss: 2.540710687637329, Classification AUC: 0.750197103786217, Learning Rate: 1.0000000000000002e-07\n",
      "Epoch 2200, Regression Loss: 2.5409021377563477, Classification AUC: 0.7501993276861778, Learning Rate: 1.0000000000000002e-07\n",
      "Epoch 2300, Regression Loss: 2.541017532348633, Classification AUC: 0.7502014938582041, Learning Rate: 1.0000000000000002e-07\n",
      "Epoch 2400, Regression Loss: 2.540896415710449, Classification AUC: 0.750203659342993, Learning Rate: 1.0000000000000002e-07\n",
      "Epoch 2500, Regression Loss: 2.540773630142212, Classification AUC: 0.7502054681516139, Learning Rate: 1.0000000000000002e-08\n",
      "Epoch 2600, Regression Loss: 2.5408074855804443, Classification AUC: 0.7502056433971299, Learning Rate: 1.0000000000000002e-08\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m activations \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m      5\u001b[0m model \u001b[38;5;241m=\u001b[39m WeatherPredictionNetwork(layers, activations, seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m21\u001b[39m)\n\u001b[1;32m----> 7\u001b[0m \u001b[43mtrain_and_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbath_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m256\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[10], line 7\u001b[0m, in \u001b[0;36mtrain_and_evaluate\u001b[1;34m(model, X_train, y_train, X_test, y_test, epochs, learning_rate, bath_size)\u001b[0m\n\u001b[0;32m      4\u001b[0m X_test_cp \u001b[38;5;241m=\u001b[39m cp\u001b[38;5;241m.\u001b[39marray(X_test\u001b[38;5;241m.\u001b[39mreshape(X_test\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m), dtype\u001b[38;5;241m=\u001b[39mcp\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[0;32m      5\u001b[0m y_test_cp \u001b[38;5;241m=\u001b[39m cp\u001b[38;5;241m.\u001b[39marray(y_test, dtype\u001b[38;5;241m=\u001b[39mcp\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[1;32m----> 7\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_cp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_cp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test_cp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test_cp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbath_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m predictions \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_test_cp)\n\u001b[0;32m     11\u001b[0m mae \u001b[38;5;241m=\u001b[39m cp\u001b[38;5;241m.\u001b[39mmean(cp\u001b[38;5;241m.\u001b[39mabs(predictions[:, \u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m-\u001b[39m y_test_cp[:, \u001b[38;5;241m0\u001b[39m]))\n",
      "File \u001b[1;32mc:\\Users\\patry\\Documents\\GitHub\\Weather-prediction\\weather_prediction.py:115\u001b[0m, in \u001b[0;36mWeatherPredictionNetwork.train\u001b[1;34m(self, X, y, X_test, y_test, epochs, learning_rate, batch_size)\u001b[0m\n\u001b[0;32m    113\u001b[0m     y_batch \u001b[38;5;241m=\u001b[39m y_shuffled[i:i \u001b[38;5;241m+\u001b[39m batch_size]\n\u001b[0;32m    114\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforward(X_batch)\n\u001b[1;32m--> 115\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    116\u001b[0m     \u001b[38;5;66;03m# self.clip_weights()\u001b[39;00m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m epoch \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m500\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\patry\\Documents\\GitHub\\Weather-prediction\\weather_prediction.py:85\u001b[0m, in \u001b[0;36mWeatherPredictionNetwork.backward\u001b[1;34m(self, X, y, output, learning_rate)\u001b[0m\n\u001b[0;32m     83\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_layers \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m     84\u001b[0m     z \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mz_values[i \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m---> 85\u001b[0m     delta \u001b[38;5;241m=\u001b[39m \u001b[43mcp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdeltas\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweights\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_activation_derivative(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactivations_values[i], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactivations[i \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m     86\u001b[0m     deltas\u001b[38;5;241m.\u001b[39mappend(delta)\n\u001b[0;32m     88\u001b[0m deltas\u001b[38;5;241m.\u001b[39mreverse()\n",
      "File \u001b[1;32mc:\\Users\\patry\\anaconda3\\envs\\weather\\lib\\site-packages\\cupy\\linalg\\_product.py:63\u001b[0m, in \u001b[0;36mdot\u001b[1;34m(a, b, out)\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Returns a dot product of two arrays.\u001b[39;00m\n\u001b[0;32m     45\u001b[0m \n\u001b[0;32m     46\u001b[0m \u001b[38;5;124;03mFor arrays with more than one axis, it computes the dot product along the\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     60\u001b[0m \n\u001b[0;32m     61\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;66;03m# TODO(okuta): check type\u001b[39;00m\n\u001b[1;32m---> 63\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43ma\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from weather_prediction import WeatherPredictionNetwork\n",
    "\n",
    "layers = [X_train.shape[1] * X_train.shape[2], 128, 64, 2]\n",
    "activations = [\"relu\", \"relu\"]\n",
    "model = WeatherPredictionNetwork(layers, activations, seed=21)\n",
    "\n",
    "train_and_evaluate(model, X_train, y_train, X_test, y_test, epochs=5000, learning_rate=0.01, bath_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 7752,
     "sourceId": 11375,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30822,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "weather",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
