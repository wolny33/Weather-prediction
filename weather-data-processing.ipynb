{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install pandas\n",
    "# %pip install numpy\n",
    "# %pip install scikit-learn\n",
    "# %pip install kagglehub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-29T16:54:24.574362Z",
     "iopub.status.busy": "2024-12-29T16:54:24.573960Z",
     "iopub.status.idle": "2024-12-29T16:54:25.867960Z",
     "shell.execute_reply": "2024-12-29T16:54:25.866721Z",
     "shell.execute_reply.started": "2024-12-29T16:54:24.574325Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\patry\\anaconda3\\envs\\weather\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import kagglehub\n",
    "import cupy as cp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-29T16:54:25.869990Z",
     "iopub.status.busy": "2024-12-29T16:54:25.869419Z",
     "iopub.status.idle": "2024-12-29T16:54:29.158623Z",
     "shell.execute_reply": "2024-12-29T16:54:29.157504Z",
     "shell.execute_reply.started": "2024-12-29T16:54:25.869950Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "historical_hourly_weather_data_path = kagglehub.dataset_download('selfishgene/historical-hourly-weather-data')\n",
    "\n",
    "city = \"Portland\"\n",
    "\n",
    "city_attributes = pd.read_csv(f\"{historical_hourly_weather_data_path}/city_attributes.csv\")\n",
    "humidity = pd.read_csv(f\"{historical_hourly_weather_data_path}/humidity.csv\")\n",
    "pressure = pd.read_csv(f\"{historical_hourly_weather_data_path}/pressure.csv\")\n",
    "temperature = pd.read_csv(f\"{historical_hourly_weather_data_path}/temperature.csv\")\n",
    "weather_description = pd.read_csv(f\"{historical_hourly_weather_data_path}/weather_description.csv\")\n",
    "wind_speed = pd.read_csv(f\"{historical_hourly_weather_data_path}/wind_speed.csv\")\n",
    "wind_direction = pd.read_csv(f\"{historical_hourly_weather_data_path}/wind_direction.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-29T16:54:29.161394Z",
     "iopub.status.busy": "2024-12-29T16:54:29.160941Z",
     "iopub.status.idle": "2024-12-29T16:54:29.178700Z",
     "shell.execute_reply": "2024-12-29T16:54:29.177526Z",
     "shell.execute_reply.started": "2024-12-29T16:54:29.161353Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "if city not in city_attributes['City'].values:\n",
    "    raise ValueError(f\"City '{city}' does not exist in the data. Available cities are: {city_attributes['City'].unique()}\")\n",
    "\n",
    "selected_city = city_attributes[city_attributes['City'] == city].index[0]\n",
    "data_frames = [humidity, pressure, temperature, weather_description, wind_speed, wind_direction]\n",
    "\n",
    "for i, df in enumerate(data_frames):\n",
    "    df.set_index('datetime', inplace=True)\n",
    "    data_frames[i] = df.iloc[:, selected_city]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-29T16:54:29.180658Z",
     "iopub.status.busy": "2024-12-29T16:54:29.180324Z",
     "iopub.status.idle": "2024-12-29T16:54:29.674041Z",
     "shell.execute_reply": "2024-12-29T16:54:29.673014Z",
     "shell.execute_reply.started": "2024-12-29T16:54:29.180632Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "combined_data = pd.concat(data_frames, axis=1)\n",
    "combined_data.columns = [\n",
    "    'humidity', 'pressure', 'temperature', 'weather_description', \n",
    "    'wind_speed', 'wind_direction'\n",
    "]\n",
    "combined_data.index = pd.to_datetime(combined_data.index)\n",
    "\n",
    "# aggregate daily\n",
    "aggregated_data = combined_data.resample('D').agg({\n",
    "    'temperature': 'mean',\n",
    "    'humidity': 'mean',\n",
    "    'wind_speed': ['max', 'mean'],\n",
    "    'pressure': 'mean',\n",
    "    'weather_description': lambda x: x.mode()[0] if not x.mode().empty else np.nan,\n",
    "    'wind_direction': 'mean'\n",
    "})\n",
    "aggregated_data.columns = ['_'.join(col).strip('_') for col in aggregated_data.columns.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-29T16:54:30.110815Z",
     "iopub.status.busy": "2024-12-29T16:54:30.110545Z",
     "iopub.status.idle": "2024-12-29T16:54:30.116792Z",
     "shell.execute_reply": "2024-12-29T16:54:30.115861Z",
     "shell.execute_reply.started": "2024-12-29T16:54:30.110788Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# encoder = LabelEncoder()\n",
    "# aggregated_data['weather_description'] = encoder.fit_transform(aggregated_data['weather_description'])\n",
    "# weather_mapping = dict(enumerate(encoder.classes_))\n",
    "# print(\"Mapping for weather_description:\", weather_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_weather_data(data, window_size=3):\n",
    "    X, y = [], []\n",
    "    for i in range(window_size, len(data) - 1):\n",
    "        X_window = data.iloc[i-window_size:i][[\n",
    "            'temperature_mean', 'humidity_mean', 'pressure_mean', 'wind_speed_max', 'wind_speed_mean', 'wind_direction_mean'\n",
    "        ]].values\n",
    "        y_target = data.iloc[i + 1][['temperature_mean', 'wind_speed_max']].values\n",
    "\n",
    "        # encode wind speed >= 6 as binary\n",
    "        y_target[1] = 1 if y_target[1] >= 6 else 0\n",
    "        X.append(X_window)\n",
    "        y.append(y_target)\n",
    "\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "\n",
    "    # normalize X\n",
    "    X_mean = X.mean(axis=(0, 1), keepdims=True)\n",
    "    X_std = X.std(axis=(0, 1), keepdims=True)\n",
    "    X_normalized = (X - X_mean) / (X_std + 1e-9)\n",
    "\n",
    "    return X_normalized, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = preprocess_weather_data(aggregated_data, window_size=3)\n",
    "\n",
    "# split into train/test (0.7 or 0.8)\n",
    "train_size = int(0.8 * len(X))\n",
    "X_train, X_test = X[:train_size], X[train_size:]\n",
    "y_train, y_test = y[:train_size], y[train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1506, 3, 6)\n",
      "(1506, 2)\n",
      "(377, 3, 6)\n",
      "(377, 2)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(X_train)\n",
    "# print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate(model, X_train, y_train, X_test, y_test, epochs=1000, learning_rate=0.001, bath_size=128):\n",
    "    X_train_cp = cp.array(X_train.reshape(X_train.shape[0], -1), dtype=cp.float32)\n",
    "    y_train_cp = cp.array(y_train, dtype=cp.float32)\n",
    "    X_test_cp = cp.array(X_test.reshape(X_test.shape[0], -1), dtype=cp.float32)\n",
    "    y_test_cp = cp.array(y_test, dtype=cp.float32)\n",
    "\n",
    "    model.train(X_train_cp, y_train_cp, X_test_cp, y_test_cp, epochs, learning_rate, batch_size=bath_size)\n",
    "\n",
    "    predictions = model.predict(X_test_cp)\n",
    "    \n",
    "    mae = cp.mean(cp.abs(predictions[:, 0] - y_test_cp[:, 0]))\n",
    "\n",
    "    from sklearn.metrics import roc_auc_score\n",
    "    auc = roc_auc_score(cp.asnumpy(y_test_cp[:, 1]), cp.asnumpy(predictions[:, 1]))\n",
    "\n",
    "    print(f\"Test Regression MAE: {mae}\")\n",
    "    print(f\"Test Classification AUC: {auc}\")\n",
    "\n",
    "    print(\"Predictions:\" , predictions[:5, :])\n",
    "    print(\"True values:\", y_test_cp[:5, :])\n",
    "\n",
    "    return mae, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Regression Loss: 205.7767333984375, Classification AUC: 0.6998396519437997, Learning Rate: 0.001\n",
      "Test Regression MAE: 218.5678253173828, Test Classification AUC: 0.5\n",
      "Epoch 100, Regression Loss: 3.4849894046783447, Classification AUC: 0.6413361590473308, Learning Rate: 0.001\n",
      "Epoch 200, Regression Loss: 3.1545827388763428, Classification AUC: 0.6782991892891985, Learning Rate: 0.001\n",
      "Epoch 300, Regression Loss: 3.098140001296997, Classification AUC: 0.7042352070508292, Learning Rate: 0.001\n",
      "Epoch 400, Regression Loss: 2.8918004035949707, Classification AUC: 0.7179825299110798, Learning Rate: 0.001\n",
      "Epoch 500, Regression Loss: 2.9156625270843506, Classification AUC: 0.724977293369664, Learning Rate: 0.001\n",
      "Epoch 600, Regression Loss: 3.137298345565796, Classification AUC: 0.7268319485092116, Learning Rate: 0.001\n",
      "Epoch 700, Regression Loss: 2.8282148838043213, Classification AUC: 0.7309763290386966, Learning Rate: 0.001\n",
      "Epoch 800, Regression Loss: 2.894335985183716, Classification AUC: 0.7349637254572161, Learning Rate: 0.001\n",
      "Epoch 900, Regression Loss: 2.789440631866455, Classification AUC: 0.7372803624090334, Learning Rate: 0.001\n",
      "Epoch 1000, Regression Loss: 2.905228614807129, Classification AUC: 0.7387986230250838, Learning Rate: 0.001\n",
      "Test Regression MAE: 3.4817349910736084, Test Classification AUC: 0.5753596179605148\n",
      "Epoch 1100, Regression Loss: 2.9271397590637207, Classification AUC: 0.7399401217748175, Learning Rate: 0.001\n",
      "Epoch 1200, Regression Loss: 3.045330762863159, Classification AUC: 0.7442639127168345, Learning Rate: 0.001\n",
      "Epoch 1300, Regression Loss: 2.9231181144714355, Classification AUC: 0.7432547291463427, Learning Rate: 0.001\n",
      "Epoch 1400, Regression Loss: 2.767385959625244, Classification AUC: 0.7447954160639598, Learning Rate: 0.001\n",
      "Epoch 1500, Regression Loss: 2.8747217655181885, Classification AUC: 0.7485136968636816, Learning Rate: 0.001\n",
      "Epoch 1600, Regression Loss: 2.824073076248169, Classification AUC: 0.7493232863502317, Learning Rate: 0.001\n",
      "Epoch 1700, Regression Loss: 3.008223295211792, Classification AUC: 0.7517969074130141, Learning Rate: 0.001\n",
      "Epoch 1800, Regression Loss: 2.9066174030303955, Classification AUC: 0.7516623496036151, Learning Rate: 0.001\n",
      "Epoch 1900, Regression Loss: 2.8239493370056152, Classification AUC: 0.7533914174543905, Learning Rate: 0.001\n",
      "Epoch 2000, Regression Loss: 2.9354875087738037, Classification AUC: 0.754095603323578, Learning Rate: 0.001\n",
      "Test Regression MAE: 2.7756924629211426, Test Classification AUC: 0.5803826218624425\n",
      "Epoch 2100, Regression Loss: 2.8221559524536133, Classification AUC: 0.7534407553178367, Learning Rate: 0.001\n",
      "Epoch 2200, Regression Loss: 2.834357976913452, Classification AUC: 0.7529428914230609, Learning Rate: 0.001\n",
      "Epoch 2300, Regression Loss: 2.8861114978790283, Classification AUC: 0.7544275125867618, Learning Rate: 0.001\n",
      "Epoch 2400, Regression Loss: 2.8270423412323, Classification AUC: 0.7555286439936758, Learning Rate: 0.001\n",
      "Epoch 2500, Regression Loss: 2.7408251762390137, Classification AUC: 0.7577264215471906, Learning Rate: 0.0001\n",
      "Epoch 2600, Regression Loss: 2.1666464805603027, Classification AUC: 0.7587086935558021, Learning Rate: 0.0001\n",
      "Epoch 2700, Regression Loss: 2.1639654636383057, Classification AUC: 0.759843464415066, Learning Rate: 0.0001\n",
      "Epoch 2800, Regression Loss: 2.1584253311157227, Classification AUC: 0.76054989291441, Learning Rate: 0.0001\n",
      "Epoch 2900, Regression Loss: 2.156879425048828, Classification AUC: 0.7610926094123187, Learning Rate: 0.0001\n",
      "Epoch 3000, Regression Loss: 2.1861069202423096, Classification AUC: 0.7619627499130981, Learning Rate: 0.0001\n",
      "Test Regression MAE: 2.6298234462738037, Test Classification AUC: 0.5670898608118339\n",
      "Epoch 3100, Regression Loss: 2.143559217453003, Classification AUC: 0.7627185162758884, Learning Rate: 0.0001\n",
      "Epoch 3200, Regression Loss: 2.133584976196289, Classification AUC: 0.763243291732544, Learning Rate: 0.0001\n",
      "Epoch 3300, Regression Loss: 2.1308035850524902, Classification AUC: 0.763949720231888, Learning Rate: 0.0001\n",
      "Epoch 3400, Regression Loss: 2.1258907318115234, Classification AUC: 0.7644834662091701, Learning Rate: 0.0001\n",
      "Epoch 3500, Regression Loss: 2.1273772716522217, Classification AUC: 0.7653468788194795, Learning Rate: 0.0001\n",
      "Epoch 3600, Regression Loss: 2.1250417232513428, Classification AUC: 0.766037608907727, Learning Rate: 0.0001\n",
      "Epoch 3700, Regression Loss: 2.1672143936157227, Classification AUC: 0.76646370863749, Learning Rate: 0.0001\n",
      "Epoch 3800, Regression Loss: 2.1020030975341797, Classification AUC: 0.7668427131339635, Learning Rate: 0.0001\n",
      "Epoch 3900, Regression Loss: 2.1111080646514893, Classification AUC: 0.7672015339590272, Learning Rate: 0.0001\n",
      "Epoch 4000, Regression Loss: 2.110949993133545, Classification AUC: 0.7677509783474058, Learning Rate: 0.0001\n",
      "Test Regression MAE: 2.613494396209717, Test Classification AUC: 0.5564177974491875\n",
      "Epoch 4100, Regression Loss: 2.1063485145568848, Classification AUC: 0.7681568944057591, Learning Rate: 0.0001\n",
      "Epoch 4200, Regression Loss: 2.108417272567749, Classification AUC: 0.7684304952848701, Learning Rate: 0.0001\n",
      "Epoch 4300, Regression Loss: 2.0945167541503906, Classification AUC: 0.7685942072863055, Learning Rate: 0.0001\n",
      "Epoch 4400, Regression Loss: 2.0942370891571045, Classification AUC: 0.768766889808367, Learning Rate: 0.0001\n",
      "Epoch 4500, Regression Loss: 2.087249517440796, Classification AUC: 0.7691638353460939, Learning Rate: 0.0001\n",
      "Epoch 4600, Regression Loss: 2.090458869934082, Classification AUC: 0.769583207185387, Learning Rate: 0.0001\n",
      "Epoch 4700, Regression Loss: 2.090763568878174, Classification AUC: 0.7699554837913906, Learning Rate: 0.0001\n",
      "Epoch 4800, Regression Loss: 2.0767157077789307, Classification AUC: 0.7702313273006582, Learning Rate: 0.0001\n",
      "Epoch 4900, Regression Loss: 2.0953586101531982, Classification AUC: 0.7704712887274197, Learning Rate: 0.0001\n",
      "Epoch 5000, Regression Loss: 2.0734152793884277, Classification AUC: 0.7707448896065305, Learning Rate: 1e-05\n",
      "Test Regression MAE: 2.6085166931152344, Test Classification AUC: 0.5669297070642363\n",
      "Epoch 5100, Regression Loss: 2.0646555423736572, Classification AUC: 0.7707336764557474, Learning Rate: 1e-05\n",
      "Epoch 5200, Regression Loss: 2.0603857040405273, Classification AUC: 0.7707874995795068, Learning Rate: 1e-05\n",
      "Epoch 5300, Regression Loss: 2.063058853149414, Classification AUC: 0.7708188964016999, Learning Rate: 1e-05\n",
      "Epoch 5400, Regression Loss: 2.0644443035125732, Classification AUC: 0.7708592637445195, Learning Rate: 1e-05\n",
      "Epoch 5500, Regression Loss: 2.060324192047119, Classification AUC: 0.7708884179365559, Learning Rate: 1e-05\n",
      "Epoch 5600, Regression Loss: 2.0593299865722656, Classification AUC: 0.7709444836904722, Learning Rate: 1e-05\n",
      "Epoch 5700, Regression Loss: 2.061843156814575, Classification AUC: 0.7709377558000022, Learning Rate: 1e-05\n",
      "Epoch 5800, Regression Loss: 2.0580246448516846, Classification AUC: 0.7710319462665814, Learning Rate: 1e-05\n",
      "Epoch 5900, Regression Loss: 2.0578765869140625, Classification AUC: 0.7710117625951716, Learning Rate: 1e-05\n",
      "Epoch 6000, Regression Loss: 2.0579938888549805, Classification AUC: 0.7710207331157981, Learning Rate: 1e-05\n",
      "Test Regression MAE: 2.6214048862457275, Test Classification AUC: 0.5631442548482907\n",
      "Epoch 6100, Regression Loss: 2.061577558517456, Classification AUC: 0.7710566151983046, Learning Rate: 1e-05\n",
      "Epoch 6200, Regression Loss: 2.0607945919036865, Classification AUC: 0.7710745562395578, Learning Rate: 1e-05\n",
      "Epoch 6300, Regression Loss: 2.057908773422241, Classification AUC: 0.7710992251712808, Learning Rate: 1e-05\n",
      "Epoch 6400, Regression Loss: 2.0565526485443115, Classification AUC: 0.7711508056648838, Learning Rate: 1e-05\n",
      "Epoch 6500, Regression Loss: 2.057126760482788, Classification AUC: 0.7712203271997398, Learning Rate: 1e-05\n",
      "Epoch 6600, Regression Loss: 2.055248975753784, Classification AUC: 0.7712292977203665, Learning Rate: 1e-05\n",
      "Epoch 6700, Regression Loss: 2.0561017990112305, Classification AUC: 0.7712584519124028, Learning Rate: 1e-05\n",
      "Epoch 6800, Regression Loss: 2.055812120437622, Classification AUC: 0.7713122750361625, Learning Rate: 1e-05\n",
      "Epoch 6900, Regression Loss: 2.055666208267212, Classification AUC: 0.771327973447259, Learning Rate: 1e-05\n",
      "Epoch 7000, Regression Loss: 2.0562069416046143, Classification AUC: 0.7712808782139693, Learning Rate: 1e-05\n",
      "Test Regression MAE: 2.626922607421875, Test Classification AUC: 0.5586599499155551\n",
      "Epoch 7100, Regression Loss: 2.0570850372314453, Classification AUC: 0.7713100324060058, Learning Rate: 1e-05\n",
      "Epoch 7200, Regression Loss: 2.056021213531494, Classification AUC: 0.7713503997488254, Learning Rate: 1e-05\n",
      "Epoch 7300, Regression Loss: 2.0540361404418945, Classification AUC: 0.7713548850091387, Learning Rate: 1e-05\n",
      "Epoch 7400, Regression Loss: 2.058732748031616, Classification AUC: 0.7713537636940603, Learning Rate: 1e-05\n",
      "Epoch 7500, Regression Loss: 2.0553183555603027, Classification AUC: 0.7714019802424285, Learning Rate: 1.0000000000000002e-06\n",
      "Epoch 7600, Regression Loss: 2.054990291595459, Classification AUC: 0.7713817965710186, Learning Rate: 1.0000000000000002e-06\n",
      "Epoch 7700, Regression Loss: 2.0549840927124023, Classification AUC: 0.7713974949821152, Learning Rate: 1.0000000000000002e-06\n",
      "Epoch 7800, Regression Loss: 2.054816484451294, Classification AUC: 0.7713638555297654, Learning Rate: 1.0000000000000002e-06\n",
      "Epoch 7900, Regression Loss: 2.054426908493042, Classification AUC: 0.7713705834202352, Learning Rate: 1.0000000000000002e-06\n",
      "Epoch 8000, Regression Loss: 2.0542891025543213, Classification AUC: 0.7713974949821151, Learning Rate: 1.0000000000000002e-06\n",
      "Test Regression MAE: 2.6192634105682373, Test Classification AUC: 0.5631442548482907\n",
      "Epoch 8100, Regression Loss: 2.0542824268341064, Classification AUC: 0.7713907670916451, Learning Rate: 1.0000000000000002e-06\n",
      "Epoch 8200, Regression Loss: 2.0548696517944336, Classification AUC: 0.7714064655027416, Learning Rate: 1.0000000000000002e-06\n",
      "Epoch 8300, Regression Loss: 2.054713010787964, Classification AUC: 0.7713952523519583, Learning Rate: 1.0000000000000002e-06\n",
      "Epoch 8400, Regression Loss: 2.0544278621673584, Classification AUC: 0.7714087081328983, Learning Rate: 1.0000000000000002e-06\n",
      "Epoch 8500, Regression Loss: 2.054591178894043, Classification AUC: 0.7714221639138382, Learning Rate: 1.0000000000000002e-06\n",
      "Epoch 8600, Regression Loss: 2.0545313358306885, Classification AUC: 0.7714221639138382, Learning Rate: 1.0000000000000002e-06\n",
      "Epoch 8700, Regression Loss: 2.0545408725738525, Classification AUC: 0.7714244065439949, Learning Rate: 1.0000000000000002e-06\n",
      "Epoch 8800, Regression Loss: 2.054004669189453, Classification AUC: 0.7714244065439947, Learning Rate: 1.0000000000000002e-06\n",
      "Epoch 8900, Regression Loss: 2.054015874862671, Classification AUC: 0.771435619694778, Learning Rate: 1.0000000000000002e-06\n",
      "Epoch 9000, Regression Loss: 2.054481029510498, Classification AUC: 0.7714311344344649, Learning Rate: 1.0000000000000002e-06\n",
      "Test Regression MAE: 2.6189825534820557, Test Classification AUC: 0.5631442548482907\n",
      "Epoch 9100, Regression Loss: 2.05487322807312, Classification AUC: 0.7714401049550913, Learning Rate: 1.0000000000000002e-06\n",
      "Epoch 9200, Regression Loss: 2.0544273853302, Classification AUC: 0.7714333770646215, Learning Rate: 1.0000000000000002e-06\n",
      "Epoch 9300, Regression Loss: 2.053938627243042, Classification AUC: 0.7714277704892297, Learning Rate: 1.0000000000000002e-06\n",
      "Epoch 9400, Regression Loss: 2.0546321868896484, Classification AUC: 0.771435619694778, Learning Rate: 1.0000000000000002e-06\n",
      "Epoch 9500, Regression Loss: 2.0541651248931885, Classification AUC: 0.7714468328455613, Learning Rate: 1.0000000000000002e-06\n",
      "Epoch 9600, Regression Loss: 2.0537843704223633, Classification AUC: 0.771435619694778, Learning Rate: 1.0000000000000002e-06\n",
      "Epoch 9700, Regression Loss: 2.053508996963501, Classification AUC: 0.771435619694778, Learning Rate: 1.0000000000000002e-06\n",
      "Epoch 9800, Regression Loss: 2.0539674758911133, Classification AUC: 0.7714445902154047, Learning Rate: 1.0000000000000002e-06\n",
      "Epoch 9900, Regression Loss: 2.054196834564209, Classification AUC: 0.7714423475852481, Learning Rate: 1.0000000000000002e-06\n",
      "Test Regression MAE: 2.6185801029205322\n",
      "Test Classification AUC: 0.5631442548482907\n",
      "Predictions: [[281.46255   0.     ]\n",
      " [278.45752   1.     ]\n",
      " [280.3228    1.     ]\n",
      " [282.3572    1.     ]\n",
      " [284.39337   1.     ]]\n",
      "True values: [[282.38916   1.     ]\n",
      " [283.8175    1.     ]\n",
      " [283.66583   0.     ]\n",
      " [281.3604    1.     ]\n",
      " [281.385     1.     ]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array(2.61858, dtype=float32), np.float64(0.5631442548482907))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from weather_prediction import WeatherPredictionNetwork\n",
    "\n",
    "layers = [X_train.shape[1] * X_train.shape[2], 128, 64, 2]\n",
    "activations = [\"relu\", \"relu\"]\n",
    "model = WeatherPredictionNetwork(layers, activations, seed=21)\n",
    "\n",
    "train_and_evaluate(model, X_train, y_train, X_test, y_test, epochs=10000, learning_rate=0.01, bath_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 7752,
     "sourceId": 11375,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30822,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "weather",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
